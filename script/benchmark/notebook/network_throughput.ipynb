{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Utilities"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from brokenaxes import brokenaxes\n",
    "from datetime import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "source_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "project_mount_point = '/tmp/skyrise'\n",
    "aws_access_key_id_command = [\"aws\", \"--profile\", \"default\", \"configure\", \"get\", \"aws_access_key_id\"]\n",
    "aws_access_key_id = subprocess.check_output(aws_access_key_id_command, text=True).strip()\n",
    "aws_secret_access_key_command = [\"aws\", \"--profile\", \"default\", \"configure\", \"get\", \"aws_secret_access_key\"]\n",
    "aws_secret_access_key = subprocess.check_output(aws_secret_access_key_command, text=True).strip()\n",
    "\n",
    "def json_to_dataframe(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    runs = data['runs']\n",
    "    data_list = []\n",
    "\n",
    "    for run in runs:\n",
    "        parameters = run['parameters']\n",
    "        repetitions = run['repetitions']\n",
    "\n",
    "        for rep in repetitions:\n",
    "            invocations = rep['invocations']\n",
    "            throughput_upload = rep['aggregated_throughput_upload_mbps']\n",
    "            throughput_download = rep['aggregated_throughput_download_mbps']\n",
    "\n",
    "            for inv in invocations:\n",
    "                record = {\n",
    "                    'aggregated_throughput_upload_mbps': throughput_upload,\n",
    "                    'aggregated_throughput_download_mbps': throughput_download,\n",
    "                    'intervals_upload': inv['intervals_upload'],\n",
    "                    'intervals_download': inv['intervals_download'],\n",
    "                    'concurrent_instance_count': parameters['concurrent_instance_count'],\n",
    "                    'report_interval_ms': parameters['report_interval_ms']\n",
    "                }\n",
    "                data_list.append(record)\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Network Bursting\n",
    "\n",
    "## Common Network Throuhgput Measurement\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "palette = ['#029e73', '#cc78bc']\n",
    "sns.set_theme(context=\"notebook\", style=\"whitegrid\", palette=palette, font=\"Times New Roman\", font_scale=1.5)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "output_file = f\"cmake-build-release/bin/{timestamp}_concurrent_instance_counts=1_report_interval_ms=1000.json\"\n",
    "\n",
    "docker_command = [\n",
    "    \"docker\", \"run\", \"--rm\",\n",
    "    \"--volume\", f\"{source_dir}:{project_mount_point}\",\n",
    "    \"-e\" f\"AWS_ACCESS_KEY_ID={aws_access_key_id}\",\n",
    "    \"-e\" f\"AWS_SECRET_ACCESS_KEY={aws_secret_access_key}\",\n",
    "    \"hpides/skyrise:al2023-arm-20250608\",\n",
    "    f\"{project_mount_point}/cmake-build-release/bin/lambdaNetworkBenchmark\",\n",
    "    \"--function_instance_sizes_mb=7076\",\n",
    "    \"--concurrent_instance_counts=8\",\n",
    "    \"--repetition_count=1\",\n",
    "    \"--duration_s=10\",\n",
    "    \"--report_interval_ms=1000\",\n",
    "    \"--enable_download\",\n",
    "    \"--enable_upload\",\n",
    "    f\"{project_mount_point}/{output_file}\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    subprocess.run(docker_command, check=True)\n",
    "    print(\"Success.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "json_file = f\"{source_dir}/{output_file}\"\n",
    "# json_file = '../../../resources/benchmark/measurement/network_throughput/lambda/20250323_concurrent_instance_counts=1_report_interval_ms=1000.json'\n",
    "\n",
    "conversion_factor_mib = 0.95367\n",
    "df = json_to_dataframe(json_file)\n",
    "upload_intervals = np.concatenate(df['intervals_upload'].values)\n",
    "upload_intervals_new = [value * conversion_factor_mib for value in upload_intervals]\n",
    "download_intervals = np.concatenate(df['intervals_download'].values)\n",
    "download_intervals_new = [value * conversion_factor_mib for value in download_intervals]\n",
    "\n",
    "linewidth=1.5\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(upload_intervals_new)), upload_intervals_new, label=\"Outbound\", linewidth=linewidth)\n",
    "ax.plot(np.arange(len(download_intervals_new)), download_intervals_new, label=\"Inbound\", linewidth=linewidth)\n",
    "ax.set_xlabel('Time [seconds]')\n",
    "ax.set_xlim(0, 8.99)\n",
    "ax.set_ylabel('Throughput [MiB/s]', labelpad = 30)\n",
    "ax.set_ylim(0, 399)\n",
    "ax.set_yticks([0, 100, 200, 300])\n",
    "for spine in [\"top\", \"right\"]:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "ax.legend(loc=9, bbox_to_anchor=(0.88, 1.015), ncol=1)\n",
    "\n",
    "plt.savefig(\"4_2_network_bursting_configuration_1000ms.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Measurement with Fine Intervals (= 20ms)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.set_theme(context=\"notebook\", style=\"whitegrid\", font=\"Times New Roman\", font_scale=1.5)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "output_file = f\"cmake-build-release/bin/{timestamp}_concurrent_instance_counts=1_report_interval_ms=20.json\"\n",
    "\n",
    "docker_command = [\n",
    "    \"docker\", \"run\", \"--rm\",\n",
    "    \"--volume\", f\"{source_dir}:{project_mount_point}\",\n",
    "    \"-e\" f\"AWS_ACCESS_KEY_ID={aws_access_key_id}\",\n",
    "    \"-e\" f\"AWS_SECRET_ACCESS_KEY={aws_secret_access_key}\",\n",
    "    \"hpides/skyrise:al2023-arm-20250608\",\n",
    "    f\"{project_mount_point}/cmake-build-release/bin/lambdaNetworkBenchmark\",\n",
    "    \"--function_instance_sizes_mb=7076\",\n",
    "    \"--concurrent_instance_counts=1\",\n",
    "    \"--repetition_count=2\",\n",
    "    \"--duration_s=1\",\n",
    "    \"--report_interval_ms=20\",\n",
    "    \"--enable_download\",\n",
    "    \"--enable_upload\",\n",
    "    f\"{project_mount_point}/{output_file}\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    subprocess.run(docker_command, check=True)\n",
    "    print(\"Success.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "json_file = f\"{source_dir}/{output_file}\"\n",
    "# json_file = '../../../resources/benchmark/measurement/network_throughput/lambda/20250323_concurrent_instance_counts=1_report_interval_ms=20.json'\n",
    "\n",
    "report_interval_ms=20\n",
    "duration_ms=1000\n",
    "observation_count=int(duration_ms/report_interval_ms)\n",
    "conversion_factor_gib = 0.95367 / 1000\n",
    "\n",
    "sleep_array = np.full(\n",
    "  shape=observation_count,\n",
    "  fill_value=-1,\n",
    "  dtype=int\n",
    ")\n",
    "df = json_to_dataframe(json_file)\n",
    "sleep_row = {'intervals_upload': sleep_array,\n",
    "            'intervals_download': sleep_array,\n",
    "            'concurrent_instance_count': 1,\n",
    "            'report_interval_ms': report_interval_ms}\n",
    "part1 = df.iloc[:1]\n",
    "part2 = df.iloc[1:]\n",
    "df = pd.concat([part1, pd.DataFrame([sleep_row]), part2], ignore_index=True)\n",
    "\n",
    "upload_intervals = np.concatenate(df['intervals_upload'].values)\n",
    "download_intervals = np.concatenate(df['intervals_download'].values)\n",
    "upload_intervals = np.insert(upload_intervals,0, -1)\n",
    "upload_intervals_new = [value * conversion_factor_gib for value in upload_intervals]\n",
    "download_intervals_new = [value * conversion_factor_gib for value in download_intervals]\n",
    "upload_intervals_shift = upload_intervals_new[:-1]\n",
    "download_intervals = download_intervals_new\n",
    "\n",
    "linewidth=1.5\n",
    "bax = brokenaxes(xlims=((0, observation_count), (observation_count*2, len(upload_intervals_shift))),  wspace=0.075)\n",
    "bax.plot(np.arange(len(upload_intervals_shift)), upload_intervals_shift, label='Outbound', linewidth=linewidth, color='#029e73')\n",
    "bax.plot(np.arange(len(download_intervals)), download_intervals, label='Inbound', linewidth=linewidth,color='#cc78bc')\n",
    "bax.set_xlabel('Time [milliseconds] [broken axis]',labelpad = 30)\n",
    "bax.set_ylabel('Throughput [GiB/s]',labelpad = 50)\n",
    "bax.legend(loc=9, bbox_to_anchor=(0.88, 1.015), ncol=1)\n",
    "bax.grid(True)\n",
    "bax.set_ylim(0, 2.4)\n",
    "bax.axvline(x=observation_count, color='black', linestyle='--', linewidth=2)\n",
    "bax.axvline(x=observation_count*2, color='black', linestyle='--', linewidth=2)\n",
    "bax.annotate(\"sleep for 3 seconds\", xy=(observation_count, 1.25), xytext=(observation_count+1.88, 1.25), ha='center', va='center', rotation=90, fontstyle='italic')\n",
    "bax.set_xticklabels(['0', '0', '400','800', '1200'])\n",
    "bax.axs[1].set_xticklabels(['0', '4000', '4400','4800'])\n",
    "bax.set_yticks([0, 0.5, 1.0, 1.5, 2.0])\n",
    "bax.set_yticklabels(['0', '0', '0.5', '1.0', '1.5', '2.0'])\n",
    "\n",
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['ytick.left'] = True\n",
    "plt.savefig(\"4_2_network_bursting_configuration.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.subplots_adjust(top=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Measurement with Very Fine Intervals (= 2ms)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sns.set_theme(context=\"notebook\", style=\"whitegrid\", font=\"Times New Roman\", font_scale=1.5)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "output_file = f\"cmake-build-release/bin/{timestamp}_concurrent_instance_counts=1_report_interval_ms=2.json\"\n",
    "\n",
    "docker_command = [\n",
    "    \"docker\", \"run\", \"--rm\",\n",
    "    \"--volume\", f\"{source_dir}:{project_mount_point}\",\n",
    "    \"-e\" f\"AWS_ACCESS_KEY_ID={aws_access_key_id}\",\n",
    "    \"-e\" f\"AWS_SECRET_ACCESS_KEY={aws_secret_access_key}\",\n",
    "    \"hpides/skyrise:al2023-arm-20250608\",\n",
    "    f\"{project_mount_point}/cmake-build-release/bin/lambdaNetworkBenchmark\",\n",
    "    \"--function_instance_sizes_mb=7076\",\n",
    "    \"--concurrent_instance_counts=1\",\n",
    "    \"--repetition_count=2\",\n",
    "    \"--duration_s=1\",\n",
    "    \"--report_interval_ms=2\",\n",
    "    \"--enable_download\",\n",
    "    \"--enable_upload\",\n",
    "    f\"{project_mount_point}/{output_file}\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    subprocess.run(docker_command, check=True)\n",
    "    print(\"Success.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "json_file = f\"{source_dir}/{output_file}\"\n",
    "# json_file = '../../../resources/benchmark/measurement/network_throughput/lambda/20250323_concurrent_instance_counts=1_report_interval_ms=2.json'\n",
    "\n",
    "report_interval_ms=2\n",
    "duration_ms=1000\n",
    "observation_count=int(duration_ms/report_interval_ms)\n",
    "conversion_factor_gib = 0.95367 / 1000\n",
    "\n",
    "sleep_array = np.full(\n",
    "  shape=observation_count,\n",
    "  fill_value=-1,\n",
    "  dtype=int\n",
    ")\n",
    "df = json_to_dataframe(json_file)\n",
    "sleep_row = {'intervals_upload': sleep_array,\n",
    "            'intervals_download': sleep_array,\n",
    "            'concurrent_instance_count': 1,\n",
    "            'report_interval_ms': report_interval_ms}\n",
    "part1 = df.iloc[:1]\n",
    "part2 = df.iloc[1:]\n",
    "df = pd.concat([part1, pd.DataFrame([sleep_row]), part2], ignore_index=True)\n",
    "\n",
    "upload_intervals = np.concatenate(df['intervals_upload'].values)\n",
    "download_intervals = np.concatenate(df['intervals_download'].values)\n",
    "upload_intervals = np.insert(upload_intervals,0, -1)\n",
    "upload_intervals_new = [value * conversion_factor_gib for value in upload_intervals]\n",
    "download_intervals_new = [value * conversion_factor_gib for value in download_intervals]\n",
    "upload_intervals_shift = upload_intervals_new[:-1]\n",
    "download_intervals = download_intervals_new\n",
    "\n",
    "linewidth=0.75\n",
    "bax = brokenaxes(xlims=((0, observation_count), (observation_count*2, len(upload_intervals_shift))),  wspace=0.075)\n",
    "bax.plot(np.arange(len(upload_intervals_shift)), upload_intervals_shift, label='Outbound', linewidth=linewidth, color='#029e73')\n",
    "bax.plot(np.arange(len(download_intervals)), download_intervals, label='Inbound', linewidth=linewidth,color='#cc78bc')\n",
    "bax.set_xlabel('Time [milliseconds] [broken axis]',labelpad = 30)\n",
    "bax.set_ylabel('Throughput [GiB/s]',labelpad = 50)\n",
    "bax.legend(loc=9, bbox_to_anchor=(0.88, 1.015), ncol=1)\n",
    "bax.grid(True)\n",
    "bax.set_ylim(0, 3.5)\n",
    "bax.axvline(x=observation_count, color='black', linestyle='--', linewidth=2)\n",
    "bax.axvline(x=observation_count*2, color='black', linestyle='--', linewidth=2)\n",
    "bax.annotate(\"sleep for 3 seconds\", xy=(observation_count, 1.75), xytext=(observation_count+18.8, 1.75), ha='center', va='center', rotation=90, fontstyle='italic')\n",
    "bax.set_xticklabels(['0', '0', '400','800', '1200'])\n",
    "bax.axs[1].set_xticklabels(['0', '4000', '4400','4800'])\n",
    "\n",
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['ytick.left'] = True\n",
    "plt.savefig(\"4_2_network_bursting_configuration_2ms.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.subplots_adjust(top=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Scalability of Burst and Baseline Throughput"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "palette = ['#0173B2', '#DE8F05', '#029E73', '#D55E00', '#CC78BC', '#ECE133']\n",
    "sns.set_theme(context=\"notebook\", style=\"whitegrid\", palette=palette, font=\"Times New Roman\", font_scale=1.5)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "output_file = f\"cmake-build-release/bin/{timestamp}_concurrent_instance_counts=10.json\"\n",
    "\n",
    "docker_command = [\n",
    "    \"docker\", \"run\", \"--rm\",\n",
    "    \"--volume\", f\"{source_dir}:{project_mount_point}\",\n",
    "    \"-e\" f\"AWS_ACCESS_KEY_ID={aws_access_key_id}\",\n",
    "    \"-e\" f\"AWS_SECRET_ACCESS_KEY={aws_secret_access_key}\",\n",
    "    \"hpides/skyrise:al2023-arm-20250608\",\n",
    "    f\"{project_mount_point}/cmake-build-release/bin/lambdaNetworkBenchmark\",\n",
    "    \"--function_instance_sizes_mb=7076\",\n",
    "    \"--concurrent_instance_counts=8\",\n",
    "    \"--repetition_count=1\",\n",
    "    \"--duration_s=1\",\n",
    "    \"--report_interval_ms=20\",\n",
    "    \"--enable_download\",\n",
    "    \"--enable_upload\",\n",
    "    f\"{project_mount_point}/{output_file}\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    subprocess.run(docker_command, check=True)\n",
    "    print(\"Success.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "json_file = f\"{source_dir}/{output_file}\"\n",
    "json_files = [\n",
    "    '../../../cmake-build-release/bin/20250325140845_concurrent_instance_counts=1.json',\n",
    "    '../../../cmake-build-release/bin/20250325141035_concurrent_instance_counts=2.json',\n",
    "    '../../../cmake-build-release/bin/20250325143637_concurrent_instance_counts=4.json',\n",
    "    '../../../cmake-build-release/bin/20250325144654_concurrent_instance_counts=6.json',\n",
    "    '../../../cmake-build-release/bin/20250325143544_concurrent_instance_counts=8.json',\n",
    "    json_file\n",
    "    ]\n",
    "legend = ['1', '2', '4', '6', '8', '10']\n",
    "\n",
    "index = 0\n",
    "linewidth=2\n",
    "for json_file in json_files:\n",
    "    df = json_to_dataframe(json_file)\n",
    "    download_intervals = np.concatenate(df['aggregated_throughput_download_mbps'].values)\n",
    "    download_intervals_gib = (download_intervals / 1024)\n",
    "    download_intervals_gib_first = download_intervals_gib[:50]\n",
    "\n",
    "    plt.plot(np.arange(len(download_intervals_gib_first)),\n",
    "             download_intervals_gib_first,\n",
    "             label=legend[index],\n",
    "             linewidth=linewidth,\n",
    "             color=palette[index])\n",
    "\n",
    "    index = index +1\n",
    "\n",
    "plt.xlabel('Time [milliseconds]')\n",
    "plt.ylabel('Throughput [GiB/s]')\n",
    "legend = plt.legend(loc='best', ncol=2, title=\"Concurrent Invocations\")\n",
    "legend._legend_box.align = \"left\"\n",
    "plt.xlim(0, 50)\n",
    "ax = plt.gca()\n",
    "for spine in [\"top\", \"right\"]:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "plt.gca().set_xticklabels([0, 200, 400, 600, 800, 1000])\n",
    "\n",
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['ytick.left'] = True\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Scalability of Throughput in VPCs"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "files_vpc = [\n",
    "    '../../../resources/benchmark/measurement/network_throughput/lambda/28032024_concurrent_instance_counts=32_enable_vpc=true.json',\n",
    "    '../../../resources/benchmark/measurement/network_throughput/lambda/28032024_concurrent_instance_counts=64_enable_vpc=true.json',\n",
    "    '../../../resources/benchmark/measurement/network_throughput/lambda/28032024_concurrent_instance_counts=128_enable_vpc=true.json',\n",
    "    '../../../resources/benchmark/measurement/network_throughput/lambda/28032024_concurrent_instance_counts=256_enable_vpc=true.json']\n",
    "\n",
    "files_no_vpc = [\n",
    "    '../../../resources/benchmark/measurement/network_throughput/lambda/28032024_concurrent_instance_counts=32_enable_vpc=false.json',\n",
    "    '../../../resources/benchmark/measurement/network_throughput/lambda/28032024_concurrent_instance_counts=64_enable_vpc=false.json',\n",
    "    '../../../resources/benchmark/measurement/network_throughput/lambda/28032024_concurrent_instance_counts=128_enable_vpc=false.json',\n",
    "    '../../../resources/benchmark/measurement/network_throughput/lambda/28032024_concurrent_instance_counts=256_enable_vpc=false.json']\n",
    "\n",
    "linewidth=2\n",
    "report_interval_ms=20\n",
    "duration_ms=1000\n",
    "observation_count=int(duration_ms/report_interval_ms)\n",
    "fontsize=1\n",
    "sns.set_palette(\"colorblind\")\n",
    "sns.set_context(\"paper\")\n",
    "sns.set_theme(rc={'figure.figsize':(8.9,5.5)})\n",
    "sns.set(style=\"whitegrid\", font=\"Times New Roman\", font_scale=1.5)\n",
    "colors = ['#0173B2', '#DE8F05', '#029E73', '#D55E00', '#CC78BC']\n",
    "legend_vpc = ['32', '64', '128', '256']\n",
    "index = 0\n",
    "for file in files_no_vpc:\n",
    "    df = json_to_dataframe(file)\n",
    "    download_intervals = np.concatenate(df['aggregated_throughput_download_mbps'].values)\n",
    "    download_intervals_gib = (download_intervals / 1024)\n",
    "    download_intervals_gib_first = download_intervals_gib[:51]\n",
    "\n",
    "    plt.plot(np.arange(len(download_intervals_gib_first)),\n",
    "             download_intervals_gib_first,\n",
    "             label=legend_vpc[index],\n",
    "             linewidth=linewidth,\n",
    "             color=colors[index])\n",
    "\n",
    "    index = index +1\n",
    "\n",
    "legend_no_vpc = ['32 VPC', '64 VPC', '128 VPC', '256 VPC']\n",
    "index = 0\n",
    "for file in files_vpc:\n",
    "    df = json_to_dataframe(file)\n",
    "    download_intervals = np.concatenate(df['aggregated_throughput_download_mbps'].values)\n",
    "    download_intervals_gib = (download_intervals / 1024)\n",
    "    download_intervals_gib_first = download_intervals_gib[:51]\n",
    "    # Plotting the line plot\n",
    "    plt.plot(np.arange(len(download_intervals_gib_first)), download_intervals_gib_first, label=legend_no_vpc[index], linewidth=linewidth, linestyle='dashdot', color=colors[index])\n",
    "    index = index +1\n",
    "\n",
    "# Adding labels and title\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Time [milliseconds]')\n",
    "plt.ylabel('Throughput [GiB/s] [log scale]')\n",
    "legend = plt.legend(loc='best', ncol=2, title=\"Concurrent Invocations\")\n",
    "legend._legend_box.align = \"left\"\n",
    "plt.xlim(0, 50)\n",
    "#plt.xticks(np.arange(0, 50, step=10))\n",
    "ax = plt.gca()\n",
    "ax.set_yscale('log')\n",
    "ax.set_yticks([0, 1, 5, 25, 125, 250])\n",
    "ax.get_yaxis().set_major_formatter(ticker.ScalarFormatter())\n",
    "plt.ylim(0, 250)\n",
    "plt.gca().set_xticklabels([0, 200, 400, 600, 800, 1000])\n",
    "custom_ticks = [0,1,5,25,125,250]\n",
    "\n",
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['ytick.left'] = True\n",
    "plt.savefig(\"4_2_network_bursting_concurrency.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# EC2 Network Measurement"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sleep_s = 1800\n",
    "files_per_type = [\n",
    "    ['../../../resources/benchmark/measurement/network_throughput/ec2/repetition=1_instance_type=c6gd.medium_refill_sleep_seconds=1800.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=2_instance_type=c6gd.medium_refill_sleep_seconds=1800.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=1_instance_type=c6gd.medium_refill_sleep_seconds=900.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=2_instance_type=c6gd.medium_refill_sleep_seconds=900.txt'],\n",
    "    ['../../../resources/benchmark/measurement/network_throughput/ec2/repetition=1_instance_type=c6gd.large_refill_sleep_seconds=1800.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=2_instance_type=c6gd.large_refill_sleep_seconds=1800.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=1_instance_type=c6gd.large_refill_sleep_seconds=900.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=2_instance_type=c6gd.large_refill_sleep_seconds=900.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=1_instance_type=c6g.large_refill_sleep_seconds=300.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=2_instance_type=c6g.large_refill_sleep_seconds=300.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=3_instance_type=c6g.large_refill_sleep_seconds=300.txt'],\n",
    "    ['../../../resources/benchmark/measurement/network_throughput/ec2/repetition=1_instance_type=c6gd.xlarge_refill_sleep_seconds=1800.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=2_instance_type=c6gd.xlarge_refill_sleep_seconds=1800.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=1_instance_type=c6gd.xlarge_refill_sleep_seconds=900.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=2_instance_type=c6gd.xlarge_refill_sleep_seconds=900.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=1_instance_type=c6g.xlarge_refill_sleep_seconds=300.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=2_instance_type=c6g.xlarge_refill_sleep_seconds=300.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=3_instance_type=c6g.xlarge_refill_sleep_seconds=300.txt'],\n",
    "    ['../../../resources/benchmark/measurement/network_throughput/ec2/repetition=1_instance_type=c6gd.2xlarge_refill_sleep_seconds=1800.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=2_instance_type=c6gd.2xlarge_refill_sleep_seconds=1800.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=1_instance_type=c6gd.2xlarge_refill_sleep_seconds=1800.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=2_instance_type=c6gd.2xlarge_refill_sleep_seconds=900.txt'],\n",
    "    ['../../../resources/benchmark/measurement/network_throughput/ec2/repetition=1_instance_type=c6gd.4xlarge_refill_sleep_seconds=900.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=2_instance_type=c6gd.4xlarge_refill_sleep_seconds=1800.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=1_instance_type=c6gd.4xlarge_refill_sleep_seconds=900.txt',\n",
    "     '../../../resources/benchmark/measurement/network_throughput/ec2/repetition=2_instance_type=c6gd.4xlarge_refill_sleep_seconds=900.txt']]\n",
    "\n",
    "\n",
    "factor = 0.11641532182693\n",
    "categories = ['Medium', 'Large', 'XLarge', '2XLarge', '4XLarge', '8XLarge', 'Lambda']\n",
    "# Baseline bandwidth are emperically determined.\n",
    "baseline_bandwidth = [0.0582077, 0.08731149, 0.1455192, 0.291038, 0.582076, 1.5, 0.0745058]\n",
    "budget_values = []\n",
    "burst_bandwidths = []\n",
    "refill_rates = []\n",
    "\n",
    "sns.set_palette(\"colorblind\")\n",
    "sns.set_context(\"paper\")\n",
    "sns.set_theme(rc={'figure.figsize':(8.9,4.125)})\n",
    "sns.set(style=\"whitegrid\", font=\"Times New Roman\", font_scale=1.5)\n",
    "sns.set_palette(\"colorblind\")\n",
    "colors = ['#0173b2', '#c7ebff', '#de8f05', '#feedd0']\n",
    "\n",
    "def calculateBudget(df, file):\n",
    "    burst = 0\n",
    "    baseline = 0\n",
    "    budgets = [0,0]\n",
    "    duration = [0,0]\n",
    "    bursts = [0,0]\n",
    "    index = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        if (burst == 0 and index == 0):\n",
    "            burst = row['bandwidth']\n",
    "            budgets[index] += row['bandwidth']\n",
    "            duration[index] = row['second']\n",
    "        elif (burst != 0 and row['bandwidth'] > burst * 0.9):\n",
    "            budgets[index] += row['bandwidth']\n",
    "            duration[index] = row['second']\n",
    "        elif (index == 0):\n",
    "            bursts[index] = burst * factor\n",
    "            index = index + 1\n",
    "            burst = 0\n",
    "        else:\n",
    "            if (baseline == 0):\n",
    "                baseline = row['bandwidth']\n",
    "            elif (row['bandwidth'] > baseline * 1.5 and bursts[index] == 0):\n",
    "                burst = row['bandwidth']\n",
    "                bursts[index] = burst * factor\n",
    "            continue\n",
    "\n",
    "    print(\"File=\", str(file))\n",
    "    refill_rate = ((budgets[0] * 4) * factor) / sleep_s\n",
    "    for i in range(0,2):\n",
    "        print(\"i=\", i, \"Capacity (GiB)=\", (budgets[i] * 4) * factor, \"Duration=\", duration[i],\n",
    "              \"RefillRate=\", refill_rate, \"BurstBandwidth=\", (budgets[i] / duration[i]) * factor, \"Burst=\", bursts[i])\n",
    "\n",
    "    return [(budgets[0] * 4) * factor, bursts]\n",
    "\n",
    "result = []\n",
    "index = 0\n",
    "for files in files_per_type:\n",
    "    result.append([[], []])\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        intermediate = calculateBudget(df, file)\n",
    "        result[index][0].append(intermediate[0])\n",
    "        result[index][1].append(intermediate[1])\n",
    "    index = index + 1\n",
    "\n",
    "# 8XL values\n",
    "result.append([[], []])\n",
    "result[index][0].append(0)\n",
    "result[index][1].append(0)\n",
    "\n",
    "#Lambda values\n",
    "result.append([[], []])\n",
    "result[index+1][0].append(0.279397)\n",
    "#result[index+1][1].append(1.2)\n",
    "result[index+1][1].append(0.7755846757894737)\n",
    "result[index+1][1].append(1.055985167142857)\n",
    "result[index+1][1].append(0.8338784516666667)\n",
    "result[index+1][1].append(1.2201412925000002)\n",
    "result[index+1][1].append(0.9760494560000001)\n",
    "result[index+1][1].append(0.932212425)\n",
    "\n",
    "print(burst_bandwidths)\n",
    "print(result)\n",
    "\n",
    "bursts_median = [np.median(result[0][1]), np.median(result[1][1]), np.median(result[2][1]), np.median(result[3][1]), np.median(result[4][1]),np.median(result[5][1]),np.median(result[6][1])]\n",
    "y_min = [np.min(result[0][1]), np.min(result[1][1]), np.min(result[2][1]), np.min(result[3][1]), np.min(result[4][1]), np.median(result[5][1]),np.min(result[6][1])]  # Minimum values\n",
    "y_max = [np.max(result[0][1]), np.max(result[1][1]), np.max(result[2][1]), np.max(result[3][1]), np.max(result[4][1]),np.median(result[5][1]),np.max(result[6][1])]  # Maximum values\n",
    "\n",
    "# Calculate the error bars\n",
    "lower_error = [bursts_median[i] - y_min[i] for i in range(7)]\n",
    "upper_error = [y_max[i] - bursts_median[i] for i in range(7)]\n",
    "\n",
    "bars = 3\n",
    "total_bar_width = 0.65\n",
    "bar_width = total_bar_width / bars\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "x = np.arange(len(categories))\n",
    "\n",
    "# Plot the first set of values on the primary y-axis\n",
    "print(\"-------\")\n",
    "print(result[1][0])\n",
    "print([np.median(result[0][0]),np.median(result[1][0]),np.median(result[2][0]),np.median(result[3][0]),np.median(result[4][0])])\n",
    "ax1.bar(x - bar_width, [np.mean(result[0][0]),np.mean(result[1][0]),np.mean(result[2][0]),np.mean(result[3][0]),np.mean(result[4][0]),\n",
    "                        np.mean(result[5][0]),np.mean(result[6][0])],\n",
    "         width=bar_width, label='Burst Capacity', color=colors[0])\n",
    "ax1.set_xlabel('Instance Type')\n",
    "ax1.set_ylabel('Burst Capacity [GiB]')\n",
    "ax1.tick_params('y')\n",
    "\n",
    "# Plot the second set of values on the secondary y-axis\n",
    "ax2.bar(x, bursts_median, yerr=[lower_error, upper_error], capsize=5, width=bar_width, label='Burst Bandwidth', color=colors[1])\n",
    "ax2.bar(x + bar_width, baseline_bandwidth, width=bar_width, label='Baseline Bandwidth', color=colors[2])\n",
    "ax2.set_ylabel('Bandwidth [GiB/s]', labelpad=10)\n",
    "\n",
    "ax2.tick_params('y')\n",
    "\n",
    "plt.text(23 * bar_width, 0.032, 'x', ha='center', va='center', color='black', family=\"monospace\", fontsize=19)\n",
    "plt.text(22 * bar_width, 0.032, 'x', ha='center', va='center', color='black', family=\"monospace\", fontsize=19)\n",
    "\n",
    "# Set the x-axis ticks and labels\n",
    "ax1.set_xticks(x, labels=categories)\n",
    "\n",
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['ytick.left'] = True\n",
    "\n",
    "ax1.grid(True)\n",
    "ax2.grid(False)\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "fig.legend(loc='upper center', ncol=3, bbox_to_anchor=(0.51, 1.00))\n",
    "fig = plt.gcf()\n",
    "\n",
    "plt.savefig('4_2_network_bursting_ec2.pdf', bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
